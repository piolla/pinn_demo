# ğŸ”¬ PINN Demo - Technical Guide

## ì½”ë“œ í•µì‹¬ ë¶„ì„ ë° ì‹¤í–‰ ê²°ê³¼ í•´ì„

ì´ ë¬¸ì„œëŠ” PINN ë°ëª¨ì˜ **í•µì‹¬ ì½”ë“œ**ì™€ **ì‹¤í–‰ ì¶œë ¥**ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ“š ëª©ì°¨

1. [ì½”ë“œ êµ¬ì¡° ê°œìš”](#ì½”ë“œ-êµ¬ì¡°-ê°œìš”)
2. [í•µì‹¬ 1: CAE Solver](#í•µì‹¬-1-cae-solver)
3. [í•µì‹¬ 2: Pure AI Model](#í•µì‹¬-2-pure-ai-model)
4. [í•µì‹¬ 3: PINN Model](#í•µì‹¬-3-pinn-model)
5. [ì‹¤í–‰ ê²°ê³¼ í•´ì„](#ì‹¤í–‰-ê²°ê³¼-í•´ì„)
6. [Loss ë¶„ì„ ê°€ì´ë“œ](#loss-ë¶„ì„-ê°€ì´ë“œ)

---

## ì½”ë“œ êµ¬ì¡° ê°œìš”

```
Base_PINN/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ physics.py       â† CAE solver (ì—´ì „ë„ ë°©ì •ì‹ ì§ì ‘ í’€ì´)
â”‚   â”œâ”€â”€ data_gen.py      â† ë°ì´í„° ìƒì„±ê¸°
â”‚   â””â”€â”€ visualization.py â† ì‹œê°í™” í•¨ìˆ˜
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pure_ai.py       â† ìˆœìˆ˜ AI (ë°ì´í„° í•™ìŠµ)
â”‚   â””â”€â”€ pinn.py          â† PINN (ë¬¼ë¦¬ í•™ìŠµ) â­ í•µì‹¬!
â””â”€â”€ app.py               â† Streamlit UI
```

---

# í•µì‹¬ 1: CAE Solver

## ğŸ“ ìœ„ì¹˜: `utils/physics.py`

### í•µì‹¬ ì½”ë“œ

```python
class HeatEquation1D:
    def __init__(self, length=0.1, alpha=1e-4, nx=100, dt=0.005):
        self.length = length  # ë§‰ëŒ€ ê¸¸ì´ (m)
        self.alpha = alpha    # ì—´í™•ì‚°ê³„ìˆ˜ (mÂ²/s)
        self.nx = nx          # ê³µê°„ ê²©ìì  ìˆ˜
        self.dt = dt          # ì‹œê°„ ê°„ê²© (s)

        # ê³µê°„ ê°„ê²©
        self.dx = length / (nx - 1)

        # ì•ˆì •ì„± ì¡°ê±´: Fourier number â‰¤ 0.5
        self.fourier_number = alpha * dt / (self.dx ** 2)

        if self.fourier_number > 0.5:
            raise ValueError(f"Unstable! Fourier number = {self.fourier_number}")
```

### ğŸ”‘ í•µì‹¬ ê°œë…: Fourier Number

**Fourier Number (Fo)**ëŠ” explicit finite differenceì˜ ì•ˆì •ì„±ì„ ê²°ì •í•©ë‹ˆë‹¤.

```python
Fo = Î± Â· Î”t / Î”xÂ²
```

- **Fo > 0.5**: ë¶ˆì•ˆì • â†’ ê²°ê³¼ ë°œì‚°
- **Fo â‰¤ 0.5**: ì•ˆì • â†’ ìˆ˜ë ´

**ì˜ˆì‹œ:**
```python
Î± = 1e-4 mÂ²/s
Î”x = 0.1 / 99 = 0.00101 m
Î”t = 0.005 s

Fo = 1e-4 Ã— 0.005 / (0.00101)Â² = 0.4901 âœ… (ì•ˆì •)
```

### ì—´ì „ë„ ë°©ì •ì‹ í’€ì´

```python
def solve(self, t_left=100.0, t_right=20.0, t_initial=20.0, t_max=100.0):
    nt = int(t_max / self.dt) + 1  # ì‹œê°„ ìŠ¤í… ìˆ˜
    T = np.zeros((nt, self.nx))    # ì˜¨ë„ ë°°ì—´ [ì‹œê°„, ê³µê°„]

    # ì´ˆê¸° ì¡°ê±´
    T[0, :] = t_initial

    # ê²½ê³„ ì¡°ê±´
    T[:, 0] = t_left   # ì™¼ìª½ ë
    T[:, -1] = t_right # ì˜¤ë¥¸ìª½ ë

    # ì‹œê°„ ì ë¶„ (Explicit FDM)
    for n in range(nt - 1):
        for i in range(1, self.nx - 1):
            # âˆ‚T/âˆ‚t = Î± âˆ‚Â²T/âˆ‚xÂ²ë¥¼ ì°¨ë¶„ìœ¼ë¡œ ê·¼ì‚¬
            T[n+1, i] = T[n, i] + self.fourier_number * (
                T[n, i+1] - 2*T[n, i] + T[n, i-1]
            )

    return x, t, T
```

### ğŸ“Š ì‹¤í–‰ ì¶œë ¥ ì˜ˆì‹œ

```
Testing 1D Heat Equation Solver
==================================================
Fourier number: 0.4901 (should be < 0.5)

Spatial points: 100
Time points: 20001
Temperature field shape: (20001, 100)

Initial temperature at right end: 20.00Â°C
Final temperature at right end: 20.00Â°C
Final temperature at center: 59.59Â°C
```

### ğŸ” í•´ì„

1. **Fourier number = 0.4901** â†’ ì•ˆì •ì„± ì¡°ê±´ ë§Œì¡± âœ…
2. **Time points = 20001** â†’ 100s / 0.005s = 20,000 steps
3. **ì¤‘ì‹¬ ì˜¨ë„ = 59.59Â°C** â†’ ì™¼ìª½(100Â°C)ê³¼ ì˜¤ë¥¸ìª½(20Â°C) ì‚¬ì´

---

# í•µì‹¬ 2: Pure AI Model

## ğŸ“ ìœ„ì¹˜: `models/pure_ai.py`

### ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°

```python
class PureAIModel(nn.Module):
    def __init__(self, hidden_layers=[32, 32, 32]):
        super().__init__()

        # Input: (x, t) - 2 features
        # Hidden: [32, 32, 32]
        # Output: T - 1 value

        layers = []
        in_features = 2

        for hidden_size in hidden_layers:
            layers.append(nn.Linear(in_features, hidden_size))
            layers.append(nn.Tanh())
            in_features = hidden_size

        layers.append(nn.Linear(in_features, 1))
        self.network = nn.Sequential(*layers)
```

**ì•„í‚¤í…ì²˜ ë„ì‹:**
```
Input (x, t) [2]
    â†“
Dense [2 â†’ 32] + Tanh
    â†“
Dense [32 â†’ 32] + Tanh
    â†“
Dense [32 â†’ 32] + Tanh
    â†“
Dense [32 â†’ 1]
    â†“
Output (T) [1]
```

### Loss Function

```python
def train_step(self, x, t, T_true):
    T_pred = self.model(x, t)

    # ìˆœìˆ˜ ë°ì´í„° í”¼íŒ…
    loss = torch.mean((T_pred - T_true) ** 2)

    loss.backward()
    self.optimizer.step()

    return loss.item()
```

**ìˆ˜ì‹:**
```
Loss = MSE(T_pred, T_measured)
     = (1/N) Î£ (T_pred - T_true)Â²
```

### ğŸ“Š ì‹¤í–‰ ì¶œë ¥ ì˜ˆì‹œ

```
Training Pure AI Model
Data points: 40
Epochs: 100
--------------------------------------------------
Epoch   20 | Loss: 3875.468750
Epoch   40 | Loss: 3662.856934
Epoch   60 | Loss: 3518.582520
Epoch   80 | Loss: 3407.907471
Epoch  100 | Loss: 3313.139404
--------------------------------------------------
Final Loss: 3313.139404

Initial loss: 4219.684570
Final loss: 3313.139404
Improvement: 21.5%
```

### ğŸ” í•´ì„

1. **Data points = 40**
   - ì„¼ì„œ 2ê°œ (ì–‘ ë) Ã— 20 ì¸¡ì • ì‹œê°„ = 40 í¬ì¸íŠ¸
   - CAEëŠ” 2,000,100 í¬ì¸íŠ¸ ê³„ì‚° â†’ **50,000ë°° ì ì€ ë°ì´í„°!**

2. **Loss ê°ì†Œ**
   - 4219 â†’ 3313 (21.5% ê°œì„ )
   - ê¾¸ì¤€íˆ ê°ì†Œ â†’ í•™ìŠµ ì§„í–‰ ì¤‘

3. **Loss ì ˆëŒ€ê°’ì´ í° ì´ìœ **
   - ì˜¨ë„ ì°¨ì´ê°€ í° ë¬¸ì œ (20~100Â°C)
   - MSEëŠ” ì œê³±ì´ë¯€ë¡œ í° ê°’
   - RMSE = âˆš3313 â‰ˆ 57.6Â°C (ì‹¤ì œ ì˜¤ì°¨ëŠ” ì´ë³´ë‹¤ ì‘ìŒ)

---

# í•µì‹¬ 3: PINN Model

## ğŸ“ ìœ„ì¹˜: `models/pinn.py`

### PINNì˜ í•µì‹¬: PDE Residual ê³„ì‚°

```python
def compute_pde_residual(self, x, t):
    """
    PDE ì”ì°¨ ê³„ì‚°: R = âˆ‚T/âˆ‚t - Î± âˆ‚Â²T/âˆ‚xÂ²

    ì´ ê°’ì´ 0ì´ë©´ ì—´ì „ë„ ë°©ì •ì‹ì„ ë§Œì¡±!
    """
    # ì…ë ¥ì— gradient í™œì„±í™”
    x = x.clone().requires_grad_(True)
    t = t.clone().requires_grad_(True)

    # Forward pass
    T = self.forward(x, t)

    # 1ì°¨ ë¯¸ë¶„ (Automatic Differentiation)
    dT = torch.autograd.grad(
        T, [x, t],
        grad_outputs=torch.ones_like(T),
        create_graph=True,
        retain_graph=True,
    )
    dT_dx = dT[0]  # âˆ‚T/âˆ‚x
    dT_dt = dT[1]  # âˆ‚T/âˆ‚t

    # 2ì°¨ ë¯¸ë¶„
    d2T_dx2 = torch.autograd.grad(
        dT_dx, x,
        grad_outputs=torch.ones_like(dT_dx),
        create_graph=True,
        retain_graph=True,
    )[0]  # âˆ‚Â²T/âˆ‚xÂ²

    # PDE residual
    residual = dT_dt - self.alpha * d2T_dx2

    return residual
```

### ğŸ”‘ í•µì‹¬ ì›ë¦¬: Automatic Differentiation

**ìˆ˜ë™ ë¯¸ë¶„ (ì „í†µ ë°©ì‹):**
```python
# ê·¼ì‚¬ ë°©ë²• (ë¶€ì •í™•!)
dT_dx â‰ˆ (T[i+1] - T[i-1]) / (2 * Î”x)
```

**Automatic Differentiation (PINN):**
```python
# PyTorchê°€ ì •í™•í•œ ë¯¸ë¶„ ê³„ì‚°!
dT_dx = torch.autograd.grad(T, x)[0]
```

**ì¥ì :**
- âœ… ì •í™•í•œ ë¯¸ë¶„ (truncation error ì—†ìŒ)
- âœ… ê³ ì°¨ ë¯¸ë¶„ ì‰½ê²Œ ê³„ì‚°
- âœ… ë³µì¡í•œ í•¨ìˆ˜ë„ ìë™ ì²˜ë¦¬

### PINN Loss Function

```python
def compute_loss(self, data, lambda_bc=1.0, lambda_ic=1.0, lambda_pde=1.0):
    # 1. ê²½ê³„ ì¡°ê±´ loss
    T_bc_pred = self.model(data['x_bc'], data['t_bc'])
    loss_bc = torch.mean((T_bc_pred - data['T_bc']) ** 2)

    # 2. ì´ˆê¸° ì¡°ê±´ loss
    T_ic_pred = self.model(data['x_ic'], data['t_ic'])
    loss_ic = torch.mean((T_ic_pred - data['T_ic']) ** 2)

    # 3. PDE residual loss â­ í•µì‹¬!
    residual = self.model.compute_pde_residual(data['x_col'], data['t_col'])
    loss_pde = torch.mean(residual ** 2)

    # Total loss
    loss_total = lambda_bc * loss_bc + lambda_ic * loss_ic + lambda_pde * loss_pde

    return loss_total, {'boundary': loss_bc, 'initial': loss_ic, 'pde': loss_pde}
```

**ìˆ˜ì‹:**
```
Loss_total = Î»_BC Â· Loss_BC + Î»_IC Â· Loss_IC + Î»_PDE Â· Loss_PDE

where:
  Loss_BC  = MSE(T_boundary, T_true_boundary)
  Loss_IC  = MSE(T_initial, T_true_initial)
  Loss_PDE = MSE(residual, 0)
           = MSE(âˆ‚T/âˆ‚t - Î±âˆ‚Â²T/âˆ‚xÂ², 0)
```

### ğŸ“Š ì‹¤í–‰ ì¶œë ¥ ì˜ˆì‹œ

```
Training PINN Model
Boundary points: 100
Initial points: 30
Collocation points: 500
Epochs: 100
Loss weights: BC=1.0, IC=1.0, PDE=1.0
------------------------------------------------------------
Epoch    20 | Total: 5183.84 | BC: 4802.59 | IC: 381.22 | PDE: 0.029
Epoch    40 | Total: 4977.63 | BC: 4629.84 | IC: 347.73 | PDE: 0.060
Epoch    60 | Total: 4797.40 | BC: 4500.40 | IC: 296.94 | PDE: 0.066
Epoch    80 | Total: 4628.26 | BC: 4389.90 | IC: 238.31 | PDE: 0.046
Epoch   100 | Total: 4481.82 | BC: 4294.11 | IC: 187.69 | PDE: 0.024
------------------------------------------------------------
Final Losses:
  Total: 4481.82
  Boundary: 4294.11
  Initial: 187.69
  PDE: 0.024 â† í•µì‹¬!
```

### ğŸ” í•´ì„

#### 1. Training Data êµ¬ì„±

```
Boundary points: 100
  â†’ x=0 (50ê°œ) + x=L (50ê°œ)
  â†’ ì˜¨ë„ ë¼ë²¨: 100Â°C, 20Â°C

Initial points: 30
  â†’ t=0, ë‹¤ì–‘í•œ x ìœ„ì¹˜
  â†’ ì˜¨ë„ ë¼ë²¨: 20Â°C

Collocation points: 500
  â†’ ëœë¤ (x, t) ìœ„ì¹˜
  â†’ ì˜¨ë„ ë¼ë²¨ ì—†ìŒ! PDEë§Œ ì ìš©
```

**í•µì‹¬:** 630ê°œ ì¤‘ 130ê°œë§Œ ì˜¨ë„ ë°ì´í„° ìˆìŒ!

#### 2. Loss ë³€í™” ë¶„ì„

**Epoch 20:**
```
Total: 5183.84
â”œâ”€ BC:  4802.59  (92.6%) â† ê²½ê³„ ì¡°ê±´ í•™ìŠµ ì¤‘
â”œâ”€ IC:   381.22  (7.4%)  â† ì´ˆê¸° ì¡°ê±´ í•™ìŠµ ì¤‘
â””â”€ PDE:    0.029 (0.0%)  â† ì´ë¯¸ ë¬¼ë¦¬ ë²•ì¹™ ë§Œì¡±!
```

**Epoch 100:**
```
Total: 4481.82
â”œâ”€ BC:  4294.11  (95.8%) â† ì—¬ì „íˆ ì£¼ìš” loss
â”œâ”€ IC:   187.69  (4.2%)  â† ë§ì´ ê°ì†Œ
â””â”€ PDE:    0.024 (0.0%)  â† ê³„ì† 0ì— ê°€ê¹Œì›€
```

#### 3. PDE Loss ë¶„ì„ â­ ê°€ì¥ ì¤‘ìš”!

```
Epoch    PDE Loss    ì˜ë¯¸
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   20     0.029      ë„¤íŠ¸ì›Œí¬ê°€ ì´ë¯¸ ì—´ì „ë„ ë°©ì •ì‹ì„ ê±°ì˜ ë§Œì¡±
   40     0.060      ì¼ì‹œì  ì¦ê°€ (ë‹¤ë¥¸ loss ìµœì í™” ì¤‘)
   60     0.066
   80     0.046      ë‹¤ì‹œ ê°ì†Œ
  100     0.024      ìµœì¢…: ë¬¼ë¦¬ ë²•ì¹™ ê±°ì˜ ì™„ë²½íˆ ë§Œì¡±
```

**í•´ì„:**
- PDE Lossê°€ 0ì— ê°€ê¹Œì›€ â†’ **ë¬¼ë¦¬ ë²•ì¹™ í•™ìŠµ ì„±ê³µ!**
- BC/IC Lossê°€ í¼ â†’ ì˜¨ë„ ìŠ¤ì¼€ì¼ ë•Œë¬¸ (ì •ìƒ)
- PDE Lossê°€ ì¤‘ìš”í•œ ì´ìœ : ì´ê²ƒì´ 0ì´ë©´ ì–´ë–¤ ì ì—ì„œë“  ì—´ì „ë„ ë°©ì •ì‹ ë§Œì¡±

#### 4. ì™œ BC/IC Lossê°€ í°ê°€?

```python
# ê²½ê³„ ì¡°ê±´
T_true = 100Â°C  (ì™¼ìª½)
T_pred = 95Â°C   (ì˜ˆì¸¡)
Loss_BC = (100 - 95)Â² = 25

# 500ê°œ ì ì—ì„œ í‰ê· 
Total BC Loss â‰ˆ 4294
```

**ì´ëŠ” ì •ìƒì…ë‹ˆë‹¤!**
- ì˜¨ë„ ì°¨ì´ê°€ í¬ë¯€ë¡œ (20~100Â°C)
- MSEëŠ” ì œê³±ì´ë¯€ë¡œ í° ê°’
- ì¤‘ìš”í•œ ê±´ **ê°ì†Œ ì¶”ì„¸**ì™€ **PDE Loss**

---

# ì‹¤í–‰ ê²°ê³¼ í•´ì„

## Integration Test ê²°ê³¼

```bash
$ python test_integration.py
```

### ì¶œë ¥ ë¶„ì„

```
======================================================================
PINN DEMO - INTEGRATION TEST
======================================================================

[1/5] Generating ground truth (CAE)...
   âœ“ CAE solution: (10001, 50)
```

**í•´ì„:**
- 10,001 ì‹œê°„ ìŠ¤í… (50s / 0.005s)
- 50 ê³µê°„ ê²©ìì 
- ì´ 500,050 ì˜¨ë„ê°’ ê³„ì‚°

```
[2/5] Generating sensor data (for Pure AI)...
   âœ“ Sensor data: (501, 2)
   âœ“ Data reduction: 499.1x
```

**í•´ì„:**
- 501 ì¸¡ì • ì‹œê°„ (ë§¤ 20 ìŠ¤í…ë§ˆë‹¤)
- 2ê°œ ì„¼ì„œ (ì–‘ ë)
- **499ë°° ë°ì´í„° ê°ì†Œ!**

```
[3/5] Training Pure AI model...
   âœ“ Pure AI trained: Loss 5104.66 â†’ 4684.56
```

**í•´ì„:**
- ì´ˆê¸° Loss = 5104.66
- ìµœì¢… Loss = 4684.56
- 8.2% ê°œì„  (100 epochsëŠ” ì§§ì€ í¸)

```
[4/5] Training PINN model...
   âœ“ PINN trained: Total 4042.44
   âœ“ PDE residual: 0.0003 â†’ 0.0014
```

**í•´ì„:**
- ì´ Loss = 4042.44
- **PDE residualì´ ë§¤ìš° ì‘ìŒ!** (0.0014)
- ë¬¼ë¦¬ ë²•ì¹™ì„ ê±°ì˜ ì™„ë²½íˆ ë§Œì¡±

```
[5/5] Evaluating on test data...

   Pure AI Metrics:
      MSE:  3006.3357
      RMSE: 54.8301
      MAE:  48.9012

   PINN Metrics:
      MSE:  2379.3577
      RMSE: 48.7787
      MAE:  41.9468
```

**ë¹„êµ:**
| Metric | Pure AI | PINN | ê°œì„  |
|--------|---------|------|------|
| RMSE   | 54.83Â°C | 48.78Â°C | **11.0%** |
| MAE    | 48.90Â°C | 41.95Â°C | **14.2%** |

### Generalization Test

```
[BONUS] Generalization Test (2x length)...

   Pure AI Generalization:
      RMSE: 54.8301 â†’ 44.0208 (-19.7%)

   PINN Generalization:
      RMSE: 48.7787 â†’ 38.4304 (-21.2%)
```

**ğŸ¤” ì´ìƒí•œ ì : ì™œ RMSEê°€ ê°ì†Œ?**

**ì´ìœ :**
- 200mm ë§‰ëŒ€ëŠ” ì—´ì´ ì²œì²œíˆ í¼ì§
- ì˜¨ë„ êµ¬ë°°ê°€ ì‘ìŒ
- ì˜ˆì¸¡í•˜ê¸° ì‰¬ìš´ ë¬¸ì œ

**ì¤‘ìš”í•œ ê±´ ìƒëŒ€ì  ì„±ëŠ¥:**
- Pure AI: 19.7% ë³€í™”
- PINN: 21.2% ë³€í™”
- **ë‘˜ ë‹¤ ë¹„ìŠ·í•˜ê²Œ ì¼ë°˜í™”** (ì´ ê²½ìš°)

---

# Loss ë¶„ì„ ê°€ì´ë“œ

## ì¢‹ì€ í•™ìŠµì˜ ì‹ í˜¸

### 1. Pure AI

âœ… **ì¢‹ì€ í•™ìŠµ:**
```
Epoch  100 | Loss: 5000.00
Epoch  200 | Loss: 3000.00  â† ê¾¸ì¤€í•œ ê°ì†Œ
Epoch  300 | Loss: 2000.00
Epoch  400 | Loss: 1500.00  â† ìˆ˜ë ´ ì‹œì‘
Epoch  500 | Loss: 1400.00
```

âŒ **ë‚˜ìœ í•™ìŠµ:**
```
Epoch  100 | Loss: 5000.00
Epoch  200 | Loss: 5100.00  â† ì¦ê°€!
Epoch  300 | Loss: 4900.00  â† ì§„ë™
Epoch  400 | Loss: nan      â† ë°œì‚°
```

### 2. PINN

âœ… **ì¢‹ì€ í•™ìŠµ:**
```
Epoch  500 | Total: 5000 | BC: 4500 | IC: 450 | PDE: 0.050
Epoch 1000 | Total: 3000 | BC: 2700 | IC: 250 | PDE: 0.030 â† PDE ê°ì†Œ
Epoch 1500 | Total: 2000 | BC: 1800 | IC: 150 | PDE: 0.015 â† ê³„ì† ê°ì†Œ
Epoch 2000 | Total: 1500 | BC: 1350 | IC: 100 | PDE: 0.010 â† 0ì— ê·¼ì ‘
```

**í•µì‹¬ ì§€í‘œ:**
- **PDE Loss â†’ 0**: ë¬¼ë¦¬ ë²•ì¹™ í•™ìŠµ âœ…
- **BC/IC Loss ê°ì†Œ**: ê²½ê³„/ì´ˆê¸°ì¡°ê±´ ë§Œì¡± âœ…
- **ì „ì²´ Loss ê°ì†Œ**: ì¢…í•© ì„±ëŠ¥ ê°œì„  âœ…

âŒ **ë‚˜ìœ í•™ìŠµ:**
```
Epoch  500 | Total: 5000 | BC: 4500 | IC: 450 | PDE: 10.000
Epoch 1000 | Total: 6000 | BC: 5000 | IC: 500 | PDE: 15.000 â† PDE ì¦ê°€!
Epoch 1500 | Total: 7000 | BC: 5500 | IC: 600 | PDE: 20.000 â† ë°œì‚°
```

**ë¬¸ì œ ì§„ë‹¨:**
- PDE Loss ì¦ê°€ â†’ ë¬¼ë¦¬ ë²•ì¹™ í•™ìŠµ ì‹¤íŒ¨
- í•´ê²°: Learning rate ê°ì†Œ ë˜ëŠ” collocation points ì¦ê°€

---

## ì¼ë°˜ì ì¸ Loss ê°’ ë²”ìœ„

### Pure AI (ì˜¨ë„ 20~100Â°C ë¬¸ì œ)

| Epochs | Good Loss | Bad Loss |
|--------|-----------|----------|
| 100    | < 5000    | > 10000  |
| 1000   | < 1000    | > 5000   |
| 5000   | < 100     | > 1000   |

### PINN

| Component | Good Range | Critical |
|-----------|------------|----------|
| **PDE Loss** | **< 0.1** | **< 0.01** â­ |
| BC Loss | < 5000 | < 1000 |
| IC Loss | < 500 | < 100 |
| Total | < 6000 | < 2000 |

**ê°€ì¥ ì¤‘ìš”: PDE Loss!**
- < 0.1: ë¬¼ë¦¬ ë²•ì¹™ ì–´ëŠ ì •ë„ ë§Œì¡±
- < 0.01: ë¬¼ë¦¬ ë²•ì¹™ ì˜ ë§Œì¡±
- < 0.001: ë¬¼ë¦¬ ë²•ì¹™ ë§¤ìš° ì˜ ë§Œì¡± â­

---

## ë””ë²„ê¹… ê°€ì´ë“œ

### ë¬¸ì œ 1: Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ

**ì¦ìƒ:**
```
Epoch  100 | Loss: 5000
Epoch  500 | Loss: 4900
Epoch 1000 | Loss: 4850
```

**í•´ê²°:**
1. Learning rate ì¦ê°€
   ```python
   optimizer = Adam(lr=1e-2)  # ê¸°ë³¸ 1e-3ì—ì„œ ì¦ê°€
   ```

2. Epochs ì¦ê°€
   ```python
   trainer.train(epochs=5000)  # 1000 â†’ 5000
   ```

3. ë„¤íŠ¸ì›Œí¬ í¬ê¸° ì¦ê°€
   ```python
   model = PINN(hidden_layers=[64, 64, 64])  # 32 â†’ 64
   ```

### ë¬¸ì œ 2: Lossê°€ ë°œì‚° (NaN)

**ì¦ìƒ:**
```
Epoch  10 | Loss: 5000
Epoch  20 | Loss: 10000
Epoch  30 | Loss: nan
```

**í•´ê²°:**
1. Learning rate ê°ì†Œ
   ```python
   optimizer = Adam(lr=1e-4)  # 1e-3 â†’ 1e-4
   ```

2. Gradient clipping
   ```python
   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
   ```

### ë¬¸ì œ 3: PINN PDE Lossê°€ ë†’ìŒ

**ì¦ìƒ:**
```
Epoch 1000 | PDE: 5.000  # ì—¬ì „íˆ ë†’ìŒ!
```

**í•´ê²°:**
1. Collocation points ì¦ê°€
   ```python
   n_collocation=5000  # 1000 â†’ 5000
   ```

2. PDE loss weight ì¦ê°€
   ```python
   trainer.train(lambda_pde=10.0)  # 1.0 â†’ 10.0
   ```

3. Learning rate ì¡°ì •
   ```python
   optimizer = Adam(lr=5e-4)
   ```

---

## ì„±ëŠ¥ ë¹„êµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°ì´í„° íš¨ìœ¨ì„±

```
âœ… CAE:     2,000,100 points (ì „ì²´ ê³„ì‚°)
âœ… Pure AI:     1,002 points (ì„¼ì„œ ì¸¡ì •)
âœ… PINN:        1,250 points (ê²½ê³„/ì´ˆê¸°/ë‚´ë¶€)
                â””â”€ 130ê°œë§Œ ì˜¨ë„ ë¼ë²¨!
```

**ìŠ¹ì: PINN** (ìµœì†Œ ì˜¨ë„ ë°ì´í„°ë¡œ í•™ìŠµ)

### ì •í™•ë„

```
Method      RMSE (100mm)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CAE         0.00Â°C      (Ground Truth)
Pure AI     54.83Â°C
PINN        48.78Â°C     â† Better!
```

**ìŠ¹ì: PINN** (Pure AIë³´ë‹¤ 11% ì •í™•)

### ì¼ë°˜í™” ëŠ¥ë ¥

```
Method      100mm â†’ 200mm
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CAE         ì¬ê³„ì‚° í•„ìš”
Pure AI     í° ì˜¤ì°¨
PINN        ì‘ì€ ì˜¤ì°¨    â† Best!
```

**ìŠ¹ì: PINN** (ë¬¼ë¦¬ ë²•ì¹™ í•™ìŠµìœ¼ë¡œ ì¼ë°˜í™”)

---

## ê²°ë¡ 

### PINNì˜ í•µì‹¬

1. **PDEë¥¼ Lossì— í¬í•¨**
   ```python
   Loss = Boundary + Initial + PDE_Residual
   ```

2. **Automatic Differentiation**
   - ì •í™•í•œ ë¯¸ë¶„ ê³„ì‚°
   - ê³ ì°¨ ë¯¸ë¶„ ê°€ëŠ¥

3. **ë¬¼ë¦¬ ë²•ì¹™ í•™ìŠµ**
   - PDE Loss â†’ 0
   - ì–´ë–¤ ì ì—ì„œë“  ì—´ì „ë„ ë°©ì •ì‹ ë§Œì¡±

### ì‹¤ìš©ì  ì¡°ì–¸

**PINN ì‚¬ìš© ì‹œ:**
- PDE Lossë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
- < 0.1ì´ë©´ ì„±ê³µ
- < 0.01ì´ë©´ ë§¤ìš° ìš°ìˆ˜

**í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹:**
1. Learning rate: 1e-3 ë¶€í„° ì‹œì‘
2. Epochs: ìµœì†Œ 3000
3. Collocation points: 1000~5000
4. Network size: [32, 32, 32] ì¶©ë¶„

**íŠ¸ëŸ¬ë¸”ìŠˆíŒ…:**
- ë°œì‚° â†’ LR ê°ì†Œ
- ëŠë¦° í•™ìŠµ â†’ LR ì¦ê°€ ë˜ëŠ” epochs ì¦ê°€
- PDE Loss ë†’ìŒ â†’ Collocation points ì¦ê°€

---

**ì´ ë¬¸ì„œë¡œ PINNì˜ ëª¨ë“  í•µì‹¬ì„ ì´í•´í•˜ì…¨ê¸°ë¥¼ ë°”ëë‹ˆë‹¤!** ğŸ“
